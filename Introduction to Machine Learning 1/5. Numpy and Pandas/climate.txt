The environmental effects of massive AI models are becoming difficult to disregard. The electricity and water used to train those systems are directly proportional to their size, and overall emissions are determined through both the number of parameters and the hardware used and datacenter efficiency as well as the carbon intensity of the local grid (Lacoste et al., 2019). As such, the sustainability AI regulation by Hacker suggests co-regulation, namely Sustainability Impact Assessments (SIA), purposeful restrictions on training, an AI emissions trade system, and consumption limits based on social utility, by asking which levers are practical, and which would the most likely to mitigate harm (Hacker, 2023).
I believe the most promising intervention is mandatory Sustainability Impact Assessments, implemented in the framework of co-regulation. SIAs are feasible to enforce in practice since they build on well understood regulatory patterns, using impact assessments and risk-based regulation already well known in other similar regimes like the data protection impact assessments of GDPR. Instead of trying to determine whether a training run ¡°deserves¡± its footprint, SIAs initially require standardized accounting of their energy and water use, carbon intensity, cooling processes, and re-training cycles. SIAs build the requisite measurement infrastructure by institutionalizing similar disclosure at training as well as at significant deployment milestones.
The combination of SIAs and co-regulation enhances their adaptability. Co-regulation refers to legal obligations of developers and deployers, third party auditors as well as technical codes established by the industry and approved by independent auditors. The regulators establish baselines and audit rights. Standardization of measures and reporting protocols is done by industry as technology advances. Greenwashing is then discouraged by auditors. This division of labor is both practical and receptive, since it enables standards to evolve with practice as it becomes established, without entrapping innovation.
The other tools in the paper are useful though relatively less prepared. Hard training limits (parameter or FLOP limits) are crude and threaten to chill socially beneficial research, particularly when lifecycle benefits are hard to measure. AI-based approach to the emission trading is a brilliant concept in theory, as it aligns incentives across industries. However, it must be accompanied by clear system boundaries, strong monitoring, reporting and verification, and leakage controls across borders. Consumption limit based on ¡°social utility¡± raises the question of legitimacy. Who determines utility amongst entertainment, education and science and on what measure? All of those are hard to solve until we have reliable, audited footprints. In both instances, SIAs are the pre-condition. No approaches can address the real hotspots without credible and comparable data.
Even SIAs, of course, have open challenges. Companies will claim secrecy over model design and energy agreements. Solution is tiered disclosure, with a summary to the accountability community, and a comprehensive annex to the regulators and auditors. Uncertainty still exists in measurements since footprints are dependent on location hour grid factors and datacenter operations. Solution is reconciled procedures and access to audit trails by the auditor and punishment to misreporting. Another real risk is jurisdictional leakage. Solution is market-access conditions, like if a model is provided in the EU (or other jurisdictions) audited SIAs are needed despite training location. Lastly, revelations without penalty may endanger performance. Solution is progressive coupling of SIAs to outcome-based targets and, when the quality of data stabilizes, specific thresholds for the highest emitting tiers.
To conclude, SIA with co-regulation is the most realistic and catalytic option, as it can be implemented today, is consistent with the current practices of governance, and preconditions the necessary groundwork of more precise instruments in the future. Making environmental accounting auditable and comparable, SIAs transform a diffuse sustainability issue into a measurable, manageable and increasingly constrained one, without precluding AI systems whose social benefits worth their costs.
References
Lacoste, Alexandre, et al., 2019, ¡®Quantifying the carbon emissions of machine learning.¡¯ arXiv preprint arXiv:1910.09700.
Hacker, P., 2023, ¡®Sustainable AI Regulation¡¯, arXiv preprint arXiv:2306.00292.
