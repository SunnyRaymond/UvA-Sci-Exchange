Turing¡¯s paper transforms the abstract question ¡®Can machines think?¡¯ into a definite, public test, the Imitation Game. Instead of speculating about the mental state within, he suggests one should look at what is observable through experimental dialogues. Of his Section 6 objections, the Argument 4 by Consciousness appears to me the strongest. It asserts that true thought needs conscious experience, awareness of meanings, intentions, or feelings and that a machine, which only plays with flip-flop 0s and 1s, does not possess this inner consciousness. I argue, following Turing, that such an objection does not defeat a scientific conception of machine thought, since its criterion is not publicly evaluable.

The consciousness objection is effective mostly in everyday life, where thinking actually means a lot. We relate understanding with hard work, surprise and doing something right. In one version of this view Turing quotes, taken as an example, is writing a sonnet because people feels like it. But as Turing observes, while private consciousness is the only admissible evidence, we reach a paradox. I can never know that another human, much less a machine, actually thinks. In real life, we avoid this by accepting a polite convention, that we treat other people as thinking because of their sustained, coherent performances in language and action. In this way, the objection sets a testing standard that cannot even be established by us human beings.

Turing is modest and methodologically correct in his counterargument. He rely on publicly testable behaviour. This does not mean lowering standards. It is an acknowledgement of what is considered as evidence in science. We already assess human understanding in a behavioural manner, by usage of oral tests, asking questions, seeking clarification and correction. When a system is capable of such things, of interpreting a poem, of defending an assertion, of correcting an error after being given feedback, of transferring insights across subjects, then it meets the same evidentiary standards that we apply to people. The point is not that the behaviour is a guarantee of consciousness. Instead, it provides us with the sole stable ground of objective judgment.

A common reply is that behaviour of machine might be ¡®mere simulation¡¯. However, that response reintroduces a subjective standard that can not be tested through scientific experiment. In comparison, Turing¡¯s Imitation Game has simple, open-ended requirements, by way of context tracking, flexible reasoning, and justification under challenge. This is very much in line with modern machine-learning practice. We do not test models on the question of whether they ¡®feel like¡¯ classifiers. We examine generalization, resistance to shift of probability distribution, and quality of responses on adversarial probing. These standards are operational, falsifiable standards, exactly the kind of criteria that Turing was trying to emphasize.

In short, the Argument 6 from Consciousness proposes a valid philosophical concern but offers an invalid test. The behavioural criterion used by Turing does not trivialize thinking. Rather, it is a kind of institutionalization of the only evidence that we can observe and share. When a machine is able to attain that standard consistently in rich, unconstrained interaction, we have good reason to say that the machine thinks, in a way relevant to inquiry and evaluation within science, which is all we need here.
